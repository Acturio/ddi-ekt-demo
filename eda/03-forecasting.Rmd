# Forecasting

El propósito de este análisis es predecir las ventas en número de transacciones (en un rango) de e-commerce de Elektra, a total  plataforma, diarias para una semana (de lunes a domingo), con cuatro días de anticipación (el jueves previo al primer día de predicción).

Teniendo este objetivo presente y una vez realizado el análisis descriptivo de la información, es factible proceder a crear y estructurar el conjunto de datos que servirá como insumo para realizar las predicciones.

El proceso de creación y estructuración de datos recibe el nombre de ingeniería de variables (feature engineering) y es la etapa en la que se crean nuevas características o atributos que contribuyen a la mejora de precisión en los pronósticos de ventas.

```{r workflow, echo=FALSE, fig.align='center', out.width='800pt', out.height='400pt'}
knitr::include_graphics("img/02-forecasting/workflow.png")
```

Es importante mencionar que **este proceso es iterativo** y no lineal. Una vez que se crean nuevas variables que potencialmente pueden mejorar la calidad predictiva del modelo, se realizan pruebas de precisión y calidad que permiten cuantificar el efecto de cada una de las variables incluidas en el modelo. Dependiendo de si la precisión aumenta, disminuye o se mantiene después de haber hecho cambios en las variables, se debe tomar la decisión de continuar aumentando variables, eliminar algunas o terminar el proceso con las actuales.

En las siguientes secciones se especifican los pasos a seguir para la construcción del modelo de aprendizaje estadístico automatizado.

## Ingeniería de variables

Para crear un modelo que permita obtener las mejores predicciones posibles, es necesario explotar la información disponible que permita encontrar los patrones relevantes de predicción. Dichos patrones pueden encontrarse en los datos históricos, sin embargo, también existen otras formas de encontrar variables importantes de predicción mediante:

* Transformación de las variables originales

* Creación de nuevas variables a partir de combinación de las originales 

* Análisis de datos anteriores (lags 1 día, 7 días, 1 año, etc)

* Datos externos (economía local, análisis de la competencia, etc)

A partir del análisis de las nuevas variables, será posible definir un conjunto de datos que permita realizar los pronósticos a lo largo del tiempo.

### Variables temporales 

Las variables temporales permiten asociar nueva información que se encuentra implícita en las fechas, por lo que naturalmente son las primeras que deben considerarse, entre ellas se encuentran:

* Día de la semana

* Mes del año

* Año

* Fechas festivas

* etc

Un caso particular de interés en la ingeniería de datos temporales, es considerar los lags-temporales de días, semanas e incluso años. Debido a la estacionalidad en las ventas, las transacciones ocurridas 1 a 15 días antes, así como las ventas del año pasado pueden servir para predecir las transacciones actuales. El siguiente gráfico muestra las transacciones a lo largo del tiempo, así como las ocurridas el año anterior:

```{r, include = FALSE}
knitr::opts_chunk$set(
  echo = FALSE, 
  fig.pos = 'H', 
  warning = FALSE,
  message = FALSE
  )
options(tinytex.verbose = TRUE)
options(Encoding='UTF-8')
```

```{r}
library(tidyverse)
library(corrplot)
library(heatmaply)
library(fpp3)
library(tsibble)
library(DataExplorer)
library(forecast)
library(skimr)
library(kableExtra)
library(lubridate)
library(magrittr)
library(ranger)

library(tidymodels)
library(workflowsets)
library(timetk)
library(modeltime)
library(sknifedatar)
library(gt)

ts_full_data <- readRDS("data/ts_full_data.rds")

ts_full_data %>% 
  mutate(
    dia_semana = wday(fecha, label = T, abbr = F),
    mes = month(fecha, label = T, abbr = F),
    anio = year(fecha)) %>% 
  relocate(dia_semana, .after = fecha) %>% 
  relocate(mes, .after = dia_semana) %>% 
  relocate(anio, .after = mes) %>% 
  select(fecha, dia_semana, mes, anio, transacciones = gtics_transacciones) %>% 
  mutate(yoy =  fecha - as.period(dweeks(52))) %>% 
  left_join(
    ts_full_data %>% select(fecha, yoy_transacciones = gtics_transacciones),
    by = c("yoy" = "fecha")
  ) %>% 
  arrange(desc(fecha)) %>% 
  filter(fecha >= '2021-05-01') %>% 
  pivot_longer(cols = matches("transacciones"), names_to = "Año", values_to = "transacciones") %>% 
  mutate(`Año` = case_when(
    `Año` == "transacciones" ~ "Actual",
    TRUE ~ "Anterior"
  )) %>% 
  ggplot(aes(x = fecha, y = transacciones, colour = `Año`)) +
  geom_line() + 
  scale_x_date(date_breaks = "1 month") +
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1)) +
  ggtitle("Comparación con transacciones de año previo (Rho=0.42)")
```

Al calcular la correlación entre las ventas actuales y las ocurridas el año pasado, se reporta una correlación de 0.42, lo que sugiere que sí existe una mediana correlación con las transacciones del año anterior.


```{r, eval=FALSE}
library(zoo)

ts_full_data %>% 
  mutate(gtics_transacciones_mean7 =  zoo::rollmean(gtics_transacciones, k = 7, fill = NA, align = "right")) %>% 
  relocate(gtics_transacciones_mean7, .after = fecha) %>% 
  relocate(gtics_transacciones, .after = fecha) %>% 
  filter(fecha >= '2021-01-01') %>% 
  select(fecha, gtics_transacciones, gtics_transacciones_mean7) %>% 
  ggplot(aes(x = fecha)) +
  geom_line(aes(y = gtics_transacciones, colour = "Real")) +
  geom_line(aes(y = gtics_transacciones_mean7, colour = "Media móvil")) +
  scale_color_manual(name = "", values=c("Media móvil" = "blue", "Real" = "darkgray")) +
  ggtitle("Cálculo de media móvil") +
  ylab("Transacciones") + xlab("Fecha") +
  theme_classic()
```


## Partición

El proceso para desarrollar un modelo predictivo implica necesariamente particionar la información de modo que un porcentaje sea usado para su la detección de comportamiento y patrones relevantes para la predicción y el resto de la información sea usado para realizar predicciones. A estas particiones se les conoce como partición de entrenamiento (training) y de prueba (testing). En este segundo conjunto sí se conoce la respuesta a predecir, pero no se usa en el entrenamiento. Su uso es mediante *backtesting*. Se realizan los pronósticos sobre el periodo de tiempo disponible y posteriormente se comparan las predicciones con el valor real para determinar el mejor modelo a seleccionar y estimar el error futuro. 

```{r}
model_data <- ts_full_data %>% 
  select(fecha, transacciones = gtics_transacciones,
         contains("costo")) %>% 
  mutate(yoy =  fecha - as.period(dweeks(52))) %>% 
  left_join(
    ts_full_data %>% select(fecha, yoy_transacciones = gtics_transacciones),
    by = c("yoy" = "fecha")
  ) %>% 
  as_tibble()

model_data %>% 
  as_tibble() %>% 
  initial_time_split(prop = 0.9) %>% 
  tk_time_series_cv_plan() %>% 
  plot_time_series_cv_plan(fecha, transacciones)
```
En el gráfico anterior se presenta la partición del conjunto de información disponible. A esta partición le corresponde el 90% a entrenamiento y el resto a prueba.

Adicionalmente, para tomar las mejores decisiones en cuanto a la configuración del modelo, se realizan distintas particiones que entrenan el modelo con una proporción de datos y se realiza una predicción de un mes hacia adelante. Posteriormente, se vuelve a crear un modelo y se predice el mes siguiente. A partir de esta técnica de validación cruzada se toma la decisión de los parámetros que mejor funcionan a través del tiempo. El siguiente diagrama muestra lo mencionado.


```{r}
lambda1 <- forecast::BoxCox.lambda(model_data$transacciones, method = "guerrero")
lambda2 <- forecast::BoxCox.lambda(model_data$transacciones, method = "loglik")

model_data2 <- model_data %>% 
  mutate(
    #transacciones = forecast::BoxCox(transacciones, lambda = lambda1),
    transacciones = log(transacciones),
    festivo = case_when(
      between(fecha, as_date("2021-04-27"), as_date('2021-05-16')) ~ "Sí",
      between(fecha, as_date("2022-04-28"), as_date('2022-05-14')) ~ "Sí",
      between(fecha, as_date("2020-11-09"), as_date('2020-11-20')) ~ "Sí",
      between(fecha, as_date("2021-11-10"), as_date('2021-11-16')) ~ "Sí",
      between(fecha, as_date("2020-11-25"), as_date('2020-11-30')) ~ "Sí",
      between(fecha, as_date("2021-11-25"), as_date('2021-11-30')) ~ "Sí",
      between(fecha, as_date("2020-07-12"), as_date('2020-07-25')) ~ "Sí",
      between(fecha, as_date("2021-07-12"), as_date('2021-07-25')) ~ "Sí",
      between(fecha, as_date("2021-03-24"), as_date('2021-03-28')) ~ "Sí",
      between(fecha, as_date("2022-03-24"), as_date('2022-03-28')) ~ "Sí",
      between(fecha, as_date("2020-07-12"), as_date('2020-07-17')) ~ "Sí",
      between(fecha, as_date("2021-07-12"), as_date('2021-07-17')) ~ "Sí",
      between(fecha, as_date("2022-07-12"), as_date('2022-07-17')) ~ "Sí",
      between(fecha, as_date("2021-09-24"), as_date('2021-09-30')) ~ "Sí",
      between(fecha, as_date("2022-09-24"), as_date('2022-09-30')) ~ "Sí",
      TRUE ~ "No")
  )

split_data <- model_data2 %>% initial_time_split(prop = 0.9)
training_data <- training(split_data)
testing_data <- testing(split_data)

tscv_data <- time_series_cv(
  data = training_data,
  date_var = fecha,
  initial = "13 months",
  assess = "1 months",
  skip = "1 months",
  cumulative = TRUE,
  slice_limit = 4
  ) 

tscv_data %>% 
  tk_time_series_cv_plan() %>% 
  plot_time_series_cv_plan(fecha, transacciones)
```

## Ajuste de modelos

```{r, include=FALSE}
recipe_time <- model_data2 %>% 
  recipe(transacciones ~ fecha, data = .) %>%
  step_timeseries_signature(fecha) %>% 
  step_date(fecha, features = c('dow','quarter', 'month', 'semester')) %>% 
  step_lag(transacciones, lag = 365) %>% 
  step_fourier(fecha, period = 365/12, K = 5)

recipe_base <- model_data2 %>% 
  recipe(transacciones~., data=.) %>%
  step_date(fecha, features = c('dow', 'month')) %>% 
  step_fourier(fecha, period = 365/12, K = 10) %>% 
  step_mutate(yoy_transacciones = log(yoy_transacciones)) %>% 
  step_ts_impute(all_numeric_predictors(), period=365) %>%  
  step_mutate(
    adstock_fb_costo_link_clicks = stats::filter(fb_costo_link_clicks, filter = 0.197, method = "recursive"),
    adstock_gads_costo_buscar = stats::filter(gads_costo_buscar, filter = 0.535, method = "recursive"),
    adstock_fb_costo_reach = stats::filter(fb_costo_reach, filter = 0.482, method = "recursive"),
    adstock_gads_costo_display = stats::filter(gads_costo_display, filter = 0.685, method = "recursive"),
    adstock_gads_costo_vídeo = stats::filter(gads_costo_vídeo, filter = 0.675, method = "recursive"),
    
    adstock_gads_costo_shopping = stats::filter(gads_costo_shopping, filter = 1.048, method = "recursive"),
    adstock_gads_costo_rendimiento_máximo = stats::filter(gads_costo_rendimiento_máximo, filter = 0.338, method = "recursive"),
    adstock_fb_costo_video_views = stats::filter(fb_costo_video_views, filter = 1.043, method = "recursive"),
    adstock_fb_costo_post_engagement = stats::filter(fb_costo_post_engagement, filter = 0.945, method = "recursive"),
    adstock_fb_costo_product_catalog_sales = stats::filter(fb_costo_product_catalog_sales, filter = 0.50, method = "recursive"),
    adstock_fb_costo_messages = stats::filter(fb_costo_messages, filter = 1.043, method = "recursive"),
    adstock_fb_costo_outcome_awareness = stats::filter(fb_costo_outcome_awareness, filter = 0.329, method = "recursive"),
    ) %>% 
  step_mutate(ratio_trans_costo = yoy_transacciones/adstock_fb_costo_link_clicks) %>% 
  step_dummy(fecha_dow, fecha_month) %>% 
  step_dummy(festivo) %>% 
  step_interact(~starts_with("fecha_dow"):yoy_transacciones) %>% 
  step_interact(~starts_with("festivo"):yoy_transacciones) %>% 
  #step_interact(~festivo_Sí:gtics_usuarios) %>% 
  step_interact(~festivo_Sí:adstock_fb_costo_link_clicks) %>% 
  step_interact(~festivo_Sí:adstock_gads_costo_buscar) %>% 
  step_interact(~festivo_Sí:adstock_fb_costo_reach) %>% 
  step_interact(~festivo_Sí:adstock_gads_costo_display) %>% 
  step_interact(~festivo_Sí:adstock_gads_costo_vídeo) %>% 
  
  step_interact(~fecha_dow_lun:adstock_fb_costo_link_clicks) %>%
  step_interact(~fecha_dow_mar:adstock_fb_costo_link_clicks) %>%
  step_interact(~fecha_dow_mié:adstock_fb_costo_link_clicks) %>%
  step_interact(~fecha_dow_jue:adstock_fb_costo_link_clicks) %>%
  step_interact(~fecha_dow_vie:adstock_fb_costo_link_clicks) %>%
  step_interact(~fecha_dow_sáb:adstock_fb_costo_link_clicks) %>%
  
  step_interact(~fecha_dow_lun:adstock_gads_costo_buscar) %>%
  step_interact(~fecha_dow_mar:adstock_gads_costo_buscar) %>%
  step_interact(~fecha_dow_mié:adstock_gads_costo_buscar) %>%
  step_interact(~fecha_dow_jue:adstock_gads_costo_buscar) %>%
  step_interact(~fecha_dow_vie:adstock_gads_costo_buscar) %>%
  step_interact(~fecha_dow_sáb:adstock_gads_costo_buscar) %>%
  
  step_interact(~fecha_dow_lun:adstock_fb_costo_reach) %>%
  step_interact(~fecha_dow_mar:adstock_fb_costo_reach) %>%
  step_interact(~fecha_dow_mié:adstock_fb_costo_reach) %>%
  step_interact(~fecha_dow_jue:adstock_fb_costo_reach) %>%
  step_interact(~fecha_dow_vie:adstock_fb_costo_reach) %>%
  step_interact(~fecha_dow_sáb:adstock_fb_costo_reach) %>%
  
  step_interact(~fecha_dow_lun:adstock_gads_costo_display) %>%
  step_interact(~fecha_dow_mar:adstock_gads_costo_display) %>%
  step_interact(~fecha_dow_mié:adstock_gads_costo_display) %>%
  step_interact(~fecha_dow_jue:adstock_gads_costo_display) %>%
  step_interact(~fecha_dow_vie:adstock_gads_costo_display) %>%
  step_interact(~fecha_dow_sáb:adstock_gads_costo_display) %>%
  
  step_interact(~fecha_dow_lun:adstock_gads_costo_vídeo) %>%
  step_interact(~fecha_dow_mar:adstock_gads_costo_vídeo) %>%
  step_interact(~fecha_dow_mié:adstock_gads_costo_vídeo) %>%
  step_interact(~fecha_dow_jue:adstock_gads_costo_vídeo) %>%
  step_interact(~fecha_dow_vie:adstock_gads_costo_vídeo) %>%
  step_interact(~fecha_dow_sáb:adstock_gads_costo_vídeo) %>%

  step_interact(~fecha_dow_lun:adstock_gads_costo_rendimiento_máximo) %>%
  step_interact(~fecha_dow_mar:adstock_gads_costo_rendimiento_máximo) %>%
  step_interact(~fecha_dow_mié:adstock_gads_costo_rendimiento_máximo) %>%
  step_interact(~fecha_dow_jue:adstock_gads_costo_rendimiento_máximo) %>%
  step_interact(~fecha_dow_vie:adstock_gads_costo_rendimiento_máximo) %>%
  step_interact(~fecha_dow_sáb:adstock_gads_costo_rendimiento_máximo) %>%
  step_rm(
    yoy, 
    fb_costo_video_views,
    fb_costo_messages
    #fb_costo_link_clicks, gads_costo_buscar, fb_costo_reach, 
    #gads_costo_display, gads_costo_vídeo, gads_costo_shopping, 
    #gads_costo_rendimiento_máximo, fb_costo_post_engagement,
    #fb_costo_product_catalog_sales, fb_costo_outcome_awareness
    ) %>% 
  step_filter(fecha >= '2021-10-31') 
  
recipe_wod <- recipe_base %>% step_rm(fecha)
```

A continuación se muestra el listado de características usadas en la implementación del DEMO predictivo. La variable de respuesta son las transacciones, mientras que el resto sirve como variables explicativas.

```{r}
juice(prep(recipe_base)) %>% 
  relocate(transacciones, .after = fecha) %>% 
  names() %>% 
  tibble(variable = .) %>% 
  DT::datatable()
  
```

Es importante que todas las variables implementadas en el modelo para realizar la predicción sean conocidas con anticipación, ya que son el insumo del algoritmo predictivo. En caso de no lograr ser conocidas no podrá realizarse la predicción.

Así como se describen las características a implementar, también se nombran a continuación los modelos que serán ajustados y posteriormente comparados en su desempeño:

<!-- * Modelo SARIMA con errores boosting -->

<!-- * Modelo Prophet con errores boosting -->

<!-- * Modelo Prophet con error de tendencia logística boosting -->

* Modelo multivariado adaptativo con splines de regresión (MARS)

* Red neuronal artificial autoregresiva (NNETAR)

* Random Forest

* Regresión regularizada (ELASTICNET)

Estos 4 modelos se ponen a prueba, mostrando los siguientes resultados en el periodo de prueba.

```{r}
auto_arima_boost <- arima_boost(
  mode = "regression",
  seasonal_period = "1 weeks"
) %>% 
  set_engine('auto_arima_xgboost')

prophet_boost <- prophet_boost(
  mode = 'regression',
  seasonality_yearly = TRUE,
  seasonality_weekly = TRUE,
  trees = 10000,
  changepoint_num = 31,
  mtry = 9,
  min_n = 11,
  tree_depth = 7,
  learn_rate = 0.000114518631055946,
  loss_reduction = 18.7201361697483
  ) %>% 
  set_engine("prophet_xgboost")

# prophet_xgboost logistic
prophet_boost_log <- prophet_boost(
    mode = 'regression',
    logistic_floor = min(model_data2$transacciones),
    logistic_cap = max(model_data2$transacciones),
    growth = 'logistic',
    seasonality_yearly = TRUE,
    seasonality_weekly = TRUE,
    trees = 10000,
    changepoint_num = 40,
    mtry = 14,
    min_n = 8,
    tree_depth = 7,
    learn_rate = 6.50612195180827e-06,
    loss_reduction = 1.97514870458304
  ) %>%
  set_engine("prophet_xgboost")

# mars
mars <- mars( mode = 'regression') %>% 
  set_engine('earth')

# nnetar
nnetar_45 <- nnetar_reg(
  seasonal_period = "1 weeks",
  non_seasonal_ar = 4,
  seasonal_ar = 1,
  hidden_units = 1,
  num_networks = 44,
  penalty = 6.10364184695183e-10,
  epochs = 521
) %>% 
  set_engine("nnetar")

rf_model <- rand_forest(
  mode = "regression",
  mtry = 20,
  min_n = 20,
  trees = 10000,
  engine = "ranger"
)

glmnet <- linear_reg(
  penalty = 0.0841418848697411, 
  mixture = 0.9549767660629) %>%
  set_engine("glmnet")

```


```{r}
wfsets <- workflow_set(
  preproc = list(
    base                = recipe_base,
    wod                 = recipe_wod
  ),
  models  = list(
    #M_arima_boost       = auto_arima_boost,
    #M_prophet_boost     = prophet_boost,
    #M_prophet_boost_log = prophet_boost_log,
    M_mars              = mars,
    M_nnetar_45         = nnetar_45,
    M_random_forest     = rf_model,
    M_glmnet            = glmnet
  ),
  cross   = TRUE
) 
wfsets %<>% 
  filter(!wflow_id %in% c(
    "wod_M_arima_boost", "wod_M_prophet_boost", "wod_M_prophet_boost_log", 
    "wod_M_mars", "wod_M_nnetar_45", "wod_M_random_forest", "base_M_glmnet"))
```


```{r}
set.seed(1234)

split_prop <- 0.9
wffits <- modeltime_wfs_fit(
  .wfsets = wfsets, 
  .split_prop = split_prop, 
  .serie=model_data2
  )
```


```{r, out.width="600pt"}
modeltime_wfs_forecast(
  .wfs_results = wffits, 
  .serie = model_data2, 
  .split_prop = split_prop
  ) %>% 
  mutate(
    .value = exp(.value),
    .conf_lo = exp(.conf_lo),
    .conf_hi = exp(.conf_hi),
  ) %>% 
  plot_modeltime_forecast(
    .conf_interval_show = FALSE,
    .plotly_slider = T
  )
```





```{r}
ranking <- modeltime_wfs_rank(wffits, rank_metric = "mape", minimize = T)

wffits %>%
  select(-.fit_model, -.model_desc, -.type) %>% 
  separate(.model_id, c('recipe', 'model'), sep='_M_', remove=FALSE) %>% 
  select(-.model_id) %>% 
  arrange(mape) %>% 
  mutate_if(is.numeric, round, digits = 2) %>% 
  relocate(recipe, .after = model) %>% 
  gt() %>% 
  tab_header(title='Evaluación de modelos')
```


## Selección de mejor modelo

Al conocer las métricas de desempeño de cada uno de los modelos, es posible discernir cuáles de ellos tienen mayor potencial y deben ser ajustados con mayor precisión. Una segunda iteración de ajuste de modelos y estimación de error con intervalos de confianza al 95% sobre el conjunto de pruebas arroja los siguientes resultados


```{r}
wffits_best <- modeltime_wfs_bestmodel(
  .wfs_results = ranking, 
  .model = "top 3", 
  .metric = "mape", 
  .minimize = TRUE
  )
```

```{r, out.width="600pt"}
modeltime_wfs_forecast(.wfs_results = wffits_best, .serie = model_data2, .split_prop=split_prop)  %>% 
  mutate(
    .value = exp(.value),
    .conf_lo = exp(.conf_lo),
    .conf_hi = exp(.conf_hi),
  ) %>% 
  plot_modeltime_forecast(
    .interactive = TRUE,
    .conf_interval_alpha = 0.2,
    .plotly_slider = T
    )
```

```{r}
pred <- modeltime_wfs_forecast(
  .wfs_results = wffits_best, 
  .serie = model_data2, 
  .split_prop = split_prop)  %>% 
  mutate(
    .value = exp(.value),
    .conf_lo = exp(.conf_lo),
    .conf_hi = exp(.conf_hi),
  ) 

multi_metric <- metric_set(rmse, rsq, mae, mape, smape, mase)

model_data2 %>% select(fecha, transacciones) %>% 
  left_join(
    pred %>% select(fecha = .index, .pred = .value, .model_id)
  ) %>% 
  mutate(transacciones = exp(transacciones)) %>% 
  filter(fecha >= '2022-03-16', !is.na(.model_id)) %>%
  group_by(.model_id) %>% 
  multi_metric(truth = transacciones, estimate = .pred) %>% 
  separate(.model_id, c('recipe', 'model'), sep='_M_', remove=FALSE) %>% 
  mutate(
    model = str_remove(model, "base_M_"),
    .estimate = round(.estimate, 2)) %>% 
  select(-.model_id, -.estimator) %>%
  relocate(recipe, .after = model) %>% 
  pivot_wider(names_from = .metric, values_from = .estimate) %>% 
  arrange(mape) %>% 
  select(model, recipe, mae, mape, mase, smape,	rmse, rsq) %>% 
  gt() %>% 
  tab_header(title='Evaluación final de modelos')
  
```


Las métricas principales indican que el error absoluto medio (MAE) es aproximadamente de 30 transacciones, lo cual representa alrededor de 25% en error relativo (MAPE).

**El mejoramiento de este modelo y sus predicciones está sujeto a la acumulación de una mayor cantidad de información con alta calidad.** En caso de contar con datos de Google Ads en periodos anteriores a octubre de 2021, será posible maximizar el aprovechamiento de la información. Adicionalmente, se sugiere agregar información relacionada a:

* Calendario de contagios por COVID-19

* Calendario de fechas festivas locales especiales 

* Calendario de fechas comerciales especiales 

* Calendario de actividad comercial de la competencia

* Serie histórica de paridad dolar-quetzal.

Una vez implementadas estas características, se sugiere realizar un nuevo ajuste de modelos con ensamblaje entre los mejores de ellos, de forma que se logre crear un modelo más robusto que aproveche las ventajas de cada modelo.


```{r, eval=FALSE}
#model_data2 %>% saveRDS("data/model_data.rds")
#wffits_best %>% saveRDS("models/best_3_models.rds")

# model_data2 <- readRDS("data/model_data.rds")
# wffits_best <- readRDS("models/best_3_models.rds")

library(rsample)
library(modeltime)


split_data <- model_data2 %>% 
  select(-gtics_usuarios) %>% 
  initial_time_split(prop = 0.98)

list_models <- wffits_best %>% split(.$.model_id)

table_forecast <- purrr::map(list_models, function( .wf = list_models){
  
  .model_table <- .wf$.fit_model[[1]] %>% 
    modeltime::modeltime_calibrate(new_data = rsample::testing(split_data)) %>% 
    dplyr::mutate(.model_desc = "PREDICTION") 
  })

pred <- dplyr::bind_rows(table_forecast, .id = ".model_id") %>% 
  modeltime::modeltime_forecast(
      actual_data = rsample::training(split_data) , 
      new_data = rsample::testing(split_data) %>% select(-transacciones)
    )

pred %>% 
mutate(
    .value = exp(.value),
    .conf_lo = exp(.conf_lo),
    .conf_hi = exp(.conf_hi),
  ) %>% 
  plot_modeltime_forecast(
    .conf_interval_show = FALSE,
    .plotly_slider = T
  )


library(DT)
pred %>% 
mutate(
    .value = round(exp(.value), 0),
    .conf_lo = round(exp(.conf_lo), 0),
    .conf_hi = round(exp(.conf_hi), 0),
  ) %>% 
    filter(.key == "prediction") %>%
    select(
      date = .index,
      value = .value,
      conf_low = .conf_lo,
      conf_high = .conf_hi,
      model_id = .model_id,
    ) %>%
  arrange(desc(model_id)) %>% 
    DT::datatable(extensions = "Buttons", options = list(
      dom = "Bfrtip", 
      buttons = c('copy', 'pdf', 'print'),
      initComplete = JS(
        "function(settings, json) {",
        "$(this.api().table().header()).css({'background-color': 'orange', 'color': '#fff'});",
        "}")
    ))
```













